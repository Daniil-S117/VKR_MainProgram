# Определение ключевых точек

Мы используем следующий подход: мы извлекаем объекты с помощью предварительно обученной модели.
Затем мы используем эти объекты в качестве входных данных для сети декодера, для которой мы узнаем веса.
Этот декодер выводит тепловую карту ключевых точек. Из них мы извлекаем ключевые точки.

## Настройка обучения

### Зависимости

Вам нужны только pytorch и sklearn. Если вы настраиваете виртуальную среду, как в основном README, то это должно сработать.

### Настройка набора данных

Мы обрабатываем наши данные на изображениях, уже обрезанных до размера датчика, потому что это входные данные для модели детектора отметок в конвейере. Для этого вы можете использовать записную книжку `data_preparation/crop_resize_images_keypoint_training.ipynb`, чтобы обрезать и изменить размер калибровочных изображений.

Как только у вас будут готовы эти изображения, вы можете пометить их с помощью label-studio <https://labelstud.io/>. Убедитесь, что метки называются "начало", `конец` и `середина`. Эти имена важны для сценария создания тепловой карты. Середина категории - это все отметки, кроме начальной и конечной.

После извлечения файла Json из label-studio вы можете запустить файл генерации тепловой карты. Для этого выполните следующую команду

```shell
python heatmap_generation.py --annotation annotation.json --directory direcotory_path --size SIZE
```
Для этого путь к каталогу должен содержать папку images, в которой хранятся все изображения, аннотированные в файле json. Скрипт создает новую подпапку labels, в которую сохраняются все аннотации. В итоге структура выглядит следующим образом:
```
--direcotory_path
    --images
    --labels
```

Параметром SIZE является размер изображения с измененным размером. Входное изображение и тепловая карта будут иметь размер SIZExSIZE. Здесь выберите 448, поскольку именно такой размер входных данных мы разрешаем использовать в данный момент. При изменении модели этот параметр также может быть изменен.

Затем структурируйте свои помеченные данные следующим образом:

```
--training_data
    --train
        --images
        --labels
    --val
        --images
        --labels
```
### Обучение и валидация

Для обучения вашей модели вы можете запустить обучающий скрипт с помощью следующей команды:

```shell
python train.py --epochs epochs --learning_rate initial_learning_rate --data training_data --val --debug
```
В поле '--data' укажите папку "training_data", которую вы настроили на предыдущем шаге. Если вы установите флаг val, то валидатор будет запущен сразу после обучения, чтобы получить качественные результаты.

В качестве альтернативы вы можете проверить модель, запустив следующий скрипт:

```shell
python key_point_validator.py --model_path path/to/model.pt --data data
```

Здесь данными является тот же базовый каталог `training_data`, что и раньше.

## Технические подробности

### Кодировщик

Для извлечения функций мы используем визуальную трансформирующую модель DinoV2. <https://github.com/facebookresearch/dinov2>

## Декодер

На данный момент у нас есть для декодера очень простая модель, которая выполняет свертки 1х1 для извлеченных объектов, а затем билинейно увеличивает их дискретизацию.

### Обучение
На данный момент мы используем обучение с Adam для двоичной перекрестной потери энтропии. Также мы используем планировщик темпов обучения.
Для обучения мы также используем расширение данных, в частности, случайное обрезание, случайные повороты и случайное дрожание.

## Извлечение ключевых точек
Мы используем [Mean-Shift](https://en.wikipedia.org/wiki/Mean_shift) для определения ключевых точек.
В частности, реализация [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html)

Здесь важно выбрать правильный порог отключения. Также важно сначала нормализовать тепловую карту таким образом, чтобы значения находились в диапазоне от 0 до 1.
Точки, значения которых ниже порогового значения, не учитываются при кластеризации. Снижение порога увеличивает время вычисления. Мы выбираем пороговое значение, равное 0,5.

## Оценка прогнозируемых ключевых точек

Для сравнения и оценки ключевых точек, помимо визуального контроля, мы рассчитываем три различных показателя.
1. среднее расстояние: Каждая предсказанная точка соотносится с каждой истинной точкой по наименьшему евклидову расстоянию
Затем эти минимальные расстояния усредняются.
2. PCK: Процент правильно предсказанных истинных ключевых точек:
Доля истинных точек, в которых есть хотя бы одна предсказанная точка, близкая к ней.
3. Процент несоответствующих прогнозируемых точек:
Доля прогнозируемых точек, которые не близки ни к одной из истинных точек.
